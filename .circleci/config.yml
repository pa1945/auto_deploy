---

#
# https://circleci.com/docs/2.0/contexts/
# https://circleci.com/orbs/registry/orb/circleci/aws-cli
# https://circleci.com/orbs/registry/orb/orbss/aws-cloudformation
#

version: 2.1

orbs:
  aws-cli: circleci/aws-cli@1.2.1
  aws-s3: circleci/aws-s3@1.0.16
  # aws-cloudfront: topmonks/aws-cloudfront@1.0.0
  # aws-cloudformation: orbss/aws-cloudformation@0.1.6 # Stacks
  
commands:
  sayhello:
    description: "A very simple command for demonstration purposes"
    parameters:
      to:
        type: string
        default: "Hello World"
    steps:
      - run: echo << parameters.to >>

  com-s3-delete:
    description: "Dele S3 bucket"
    parameters:
      com-s3-param:
        type: string
        default: bucket-namex
    #docker:
    #  - image: amazon/aws-cli
    steps:
      - checkout
      - store_test_results:
          path: test-results
      - run:
          name: Delete s3 bucket
          command: |
            export AWS_ACCESS_KEY_ID=$AWS_ACCESS_KEY_ID2
            export AWS_SECRET_ACCESS_KEY=$AWS_SECRET_ACCESS_KEY2
            aws s3 rb s3://<< parameters.com-s3-param >>
            # Deletes all objects and subfolders in the bucket and 
            # then removes the bucket.
            # aws s3 rb s3://<< parameters.s3-param >> --force

  com-ec2-delete:
    description: "Delete EC2 instance"
    parameters:
      com-ec2-param:
        type: string
        default: i-5203422c    # Fake
    steps:
      - checkout
      - store_test_results:
          path: test-results
      - run:
          name: Delete ec2 instance
          command: |
            export AWS_ACCESS_KEY_ID=$AWS_ACCESS_KEY_ID2
            export AWS_SECRET_ACCESS_KEY=$AWS_SECRET_ACCESS_KEY2
            aws ec2 terminate-instances \
            --instance-ids  << parameters.com-ec2-param >>


  smoke-roll-back-ec2:
    description: "Roll back EC2 instance if smoke test fail"
    parameters:
      roll-ec2-param:
        type: string
        default: backend-uda-instancex  # For Test. Working is: backend-uda-deploy3
    steps:
      - run:
          name: Roll back ec2 instance if smoke test fail 'smoke-roll-back-ec2'
          command: |
            export AWS_ACCESS_KEY_ID=$AWS_ACCESS_KEY_ID2
            export AWS_SECRET_ACCESS_KEY=$AWS_SECRET_ACCESS_KEY2
            #
            ec2_name=<< parameters.roll-ec2-param >>
            echo "ec2 name: << parameters.roll-ec2-param >>"
            echo "ec2_name: $ec2_name"
            BACKEND_IP=$(aws ec2 describe-instances  \
              --filters Name=tag-key,Values=Name  \
              --query 'Reservations[*].Instances[*].{IP:PublicIpAddress,Name:Tags[?Key==`Name`]|[0].Value}' \
              --output text|grep $ec2_name|awk '{print $1}' )
            if curl -s  "http://${BACKEND_IP}:3030/api/status" | grep -i "status"
            then
              echo "BACKEND_IP: $BACKEND_IP"
              exit 0   # OK Smoke test OK!
            else
              echo "Should Roll back - smoke test fail"
            fi            
            #  *** from now on should exit from bash = 1 ***
            # Roll back instance if smoke test fail
            # Set .env on frontend to the IP in memstash.io (last deploy succeeded)
            # Get last succeeded instance name from 'memstash.io'
            instance_name=$(curl -H "token: 265a0727-db66-453a-8559-6b292b496502" \
              --request GET https://api.memstash.io/values/parameters.stack-create-ec2)
            echo "Instance name2: $instance_name"
            # Get the IP for the instance_name
            # Test first if it exist on 'memstash.io'
            if test "x$instance_name" = "x" -o "x$instance_name" = "xNo value matches the provided token and key."
            then
              echo "This is the first instance -  No roll back possible"
              echo "Or no information on 'memstash.io' "
              instance_name="not-found"
              exit 1	# signal evidence something wrong
            else
              echo "Instance name3: $instance_name"
              BACKEND_IP_NEW=$(aws ec2 describe-instances  \
                --filters Name=tag-key,Values=Name  \
                --query 'Reservations[*].Instances[*].{IP:PublicIpAddress,Name:Tags[?Key==`Name`]|[0].Value}' \
                --output text|grep $instance_name|awk '{print $1}' )
              echo "BACKEND_IP_NEW = $BACKEND_IP_NEW"
              echo "API_URL=http://$BACKEND_IP_NEW:3030" > frontend/.env
              # Setup the current frontend S3 bucket to access the new backend
              # Commented during testing
              # aws s3 cp frontend/.env s3://s3-uda-deploy
              # --acl public-read
              # Show me the change:
              echo "frontend/.env:"
              cat frontend/.env
              exit 1
            fi
            exit 1
            # $? from the command-line gives the exit status of the script
            #  echo "$?"

  smoke-roll-back-s3:
    description: "Roll back s3 bucket if smoke test fail"
    parameters:
      cloud-front-id:
        type: string
        default: ELP62178K8WGU
      current-s3-param:
        type: string
        default: uda-bucketx  # 'uda-bucketx' For Test. Current Working: 's3-uda-deploy'
    steps:
      - run:
          name: Roll back s3 bucket if smoke test fail 'smoke-roll-back-s3' - Check Frontend using curl
          command: |
            # set +e
            export AWS_ACCESS_KEY_ID=$AWS_ACCESS_KEY_ID2
            export AWS_SECRET_ACCESS_KEY=$AWS_SECRET_ACCESS_KEY2
            #
            cloudfront_id=<< parameters.cloud-front-id >>
            # Test s3 bucket:
            s3_name=<< parameters.current-s3-param >>
            echo "s3 name to smoke test: << parameters.current-s3-param >>"
            echo "s3_name to smoke test: $s3_name"
            FRONTEND="http://${s3_name}.s3-website-us-east-1.amazonaws.com/#/employees"
            echo "FRONTEND: $FRONTEND"
            if curl -s ${FRONTEND} | grep -i "Welcome"
            then
              exit 0    # Smoke test OK!
            else
              # exit 1    # Fail
              echo "Should Roll back - smoke test fail"
            fi            
            #  *** from now on should exit from bash = 1 ***
            # Roll back s3 if smoke test fail
            # get the old s3 bucket from 'memstash.io'
            s3_name_old=$(curl -H "token: 265a0727-db66-453a-8559-6b292b496502" \
              --request GET https://api.memstash.io/values/parameters.stack-create-s3)
            echo "Bucket name old2: $s3_name_old"
            # Test first if it exist on 'memstash.io'
            if test "x$s3_name_old" = "x" -o "x$s3_name_old" = "xNo value matches the provided token and key."
            then
              echo "This is the first s3 -  No roll back possible"
              echo "Or no data on 'memstash.io' "
              s3_name_old="not-found old s3 bucket"
              echo "Old s3 name: $s3_name_old"
              exit 1	# signal evidence something wrong
            fi
            echo "Bucket name old3: $s3_name_old"
            #
            # Download distribuion config for id 'ELP62178K8WGU'
            aws cloudfront get-distribution-config \
              --id $cloudfront_id > distribution-config-orig.json
            # Get the etag attribute to use in  '--if-match $etag_att' 
            etag_att=$(grep -i etag distribution-config-orig.json |cut -d\" -f4 )
            # New distribution config
            echo "{" > distribution-config-old0.json
            echo "etag_att: $etag_att"
            echo "1. File distribution-config-old0.json:"
            #
            cat distribution-config-old0.json
            # Delete lines 1-3, "$" is the last line, d for delete:
            sed -e '1,3d' < distribution-config-orig.json | sed '$d' >> distribution-config-old0.json
            echo "2. File distribution-config-old0.json:"
            # cat distribution-config-old0.json
            # sed to substitue the 'DomaiName'
            echo "Substitute DomainName"
            # Real production: ${s3_name} and not 's3-uda-deploy':
            cat distribution-config-old0.json | sed -e "s/s3-uda-deploy/${s3_name_old}/" > \
              distribution-config-old.json
            echo "Show me the change: DomainName 'key' and 'Value'"
            grep -i DomainName distribution-config-orig.json 
            #
            # c a t distribution-config-old.json
            echo "*** Update cloudfront new 'Origin Domain Name and Path' ***"
            aws cloudfront update-distribution --id $cloudfront_id \
              --distribution-config file://distribution-config-old.json \
              --if-match $etag_att &
            
            echo "*** CloudFront updated ***"
            sleep 30
            # exit 1
            # $ ? from the command-line gives the exit status of the script
            #  echo "$ ?"

############## jobs #################

jobs:
  aws-cli-example:
    executor: aws-cli/default
    steps:
      - checkout
      - aws-cli/setup:
          profile-name: circle-ci-uda
          # aws-access-key-id: AWS_ACCESS_KEY_ID2
          # aws-secret-access-key: AWS_SECRET_ACCESS_KEY2
          # aws-region: AWS_DEFAULT_REGION

      - run:
          name: Check aws cli version
          command: |
            aws --version
            echo $AWS_ACCESS_KEY_ID
            echo $AWS_SECRET_ACCESS_KEY
            echo $AWS_DEFAULT_REGION

      - run:
          name: Run aws cloudformation and create stack/s3-bucket
          command: |
            export AWS_ACCESS_KEY_ID=$AWS_ACCESS_KEY_ID2
            export AWS_SECRET_ACCESS_KEY=$AWS_SECRET_ACCESS_KEY2
            #
            echo "AWS keys:"
            echo $AWS_ACCESS_KEY_ID
            echo $AWS_SECRET_ACCESS_KEY
            echo $AWS_DEFAULT_REGION
            # aws cloudformation wait stack-create-complete \
            aws cloudformation deploy \
            --template-file .circleci/files/frontend.yml \
            --stack-name project-udapeople --parameter-overrides \
            ID=s3-udapeople11

  hello-world-udapeople:
    docker:
      - image: amazon/aws-cli
    steps:
      - checkout
      - run:
          name: Say Hello to Udapeople
          command: |
            echo "Udapeople: Hello World"
      - run:
          name: Check aws cli version
          command: |
            aws --version


  lint-frontend:
    docker:
      #- image: amazon/aws-cli
      # For npm
      - image: circleci/node:10.0.0
    steps:
      - checkout
      - run:
          name: cd folder/dir frontend, ls -las
          command: |
            cd frontend && ls -als
      - run:
          name: List folder/dir where we are
          command: |
            pwd ; ls -las
      - run:
          name: cd frontend, install 'npm i' and run lint
          command: |
            cd frontend; npm install ; npm run lint

  lint-backend:
    docker:
      # - image: amazon/aws-cli
      - image: circleci/node:10.0.0
    steps:
      - checkout
      - run:
          name: cd folder/dir backend, ls -las
          command: |
            cd backend && ls -als
      - run:
          name: List folder/dir where we are
          command: |
            pwd ; ls -las
      - run:
          name: cd backend, install 'npm i' and run lint
          command: |
            cd backend; npm install ; npm run lint

  run-frontend:
    docker:
      #- image: amazon/aws-cli
      - image: circleci/node:10.0.0
    steps:
      - checkout
      - run:
          name: cd folder/dir frontend, ls -las
          command: |
            cd frontend && ls -als
            npm -v && sudo npm install npm -g && npm -v

      - run:
          name: List folder/dir where we are
          command: |
            pwd ; ls -las
      - run:
          name: cd frontend, install 'npm i'
          command: |
            cd frontend; npm install
      - run:
          name: cd frontend,  and run 'npm audit'
          command: |
            cd frontend; npm audit
      - run:
          name: cd frontend, and run 'npm start'
          command: |
            cd frontend; npm run start

  run-backend:
    docker:
      # - image: amazon/aws-cli
      - image: circleci/node:10.0.0
    steps:
      - checkout
      - run:
          name: cd folder/dir backend, ls -las
          command: |
            cd backend && ls -als
            npm -v && sudo npm install npm -g && npm -v
      - run:
          name: List folder/dir where we are
          command: |
            pwd ; ls -las
      - run:
          name: cd backend, install 'npm i'
          command: |
            cd backend; npm install
      - run:
          name: cd backend,  run 'npm audit'
          command: |
            cd backend; npm audit

      - run:
          name: cd backend, run 'npm start'
          command: |
            cd backend;  npm run start

  create-frontend-s3:
    parameters:
      stack-create-s3:
        type: string
        default: uda-bucketx    # Should not exist. The current used and working is 's3-uda-deploy'
    docker:
      - image: amazon/aws-cli
    steps:
      - checkout
      - run:
          name: Check aws cli version
          command: |
            aws --version
      - run:
          name: Install/version aws cli
          command: |
            aws --version

      - run:
          name: Run aws cloudformation and create stack/s3-bucket
          command: |
            export AWS_ACCESS_KEY_ID=$AWS_ACCESS_KEY_ID2
            export AWS_SECRET_ACCESS_KEY=$AWS_SECRET_ACCESS_KEY2
            #
            echo "AWS keys:"
            echo $AWS_ACCESS_KEY_ID
            echo $AWS_SECRET_ACCESS_KEY
            echo $AWS_DEFAULT_REGION
            # aws cloudformation wait stack-create-complete \
            aws cloudformation deploy \
            --template-file .circleci/files/frontend.yml \
            --stack-name udapeople-s3 \
            --parameter-overrides ID=<< parameters.stack-create-s3 >>
            # --parameter-overrides ID=s3-udapeople
            # Save the (old?)-> new bucket arn (bucket name?) in case you 
            # need it later (for rollback).
            # Token: 265a0727-db66-453a-8559-6b292b496502
            # Key: parameters.stack-create-s3
            # echo "Stash Token: < < parameters.stash-token > >"
            curl -H "Content-Type: text/plain" \
              -H "token: 265a0727-db66-453a-8559-6b292b496502" \
              --request PUT \
              --data "<< parameters.stack-create-s3 >>" \
              https://api.memstash.io/values/parameters.stack-create-s3

  create-backend-ec2:
    parameters:
      stack-create-ec2:
        type: string
        default: stack-name-udap
    docker:
      - image: amazon/aws-cli
    steps:
      - checkout
      - run:
          name: Install/version aws cli
          command: |
            aws --version

      - run:
          name: Run aws cloudformation and create ec2 instance
          command: |
            export AWS_ACCESS_KEY_ID=$AWS_ACCESS_KEY_ID2
            export AWS_SECRET_ACCESS_KEY=$AWS_SECRET_ACCESS_KEY2
            # aws cloudformation wait stack-create-complete \
            aws cloudformation deploy \
            --template-file .circleci/files/backend.yml \
            --stack-name udapeople-ec2 \
            --parameter-overrides ID=<< parameters.stack-create-ec2 >>
            # --parameter-overrides ID=ec2-udapeople
            # Save the new back-end url for later use (the front-end needs it).
            # Token: 265a0727-db66-453a-8559-6b292b496502
            # Key: parameters.stack-create-ec2
            # echo "Stash Token: < < parameters.stash-token > >"
            curl -H "Content-Type: text/plain" \
              -H "token: 265a0727-db66-453a-8559-6b292b496502" \
              --request PUT \
              --data "<< parameters.stack-create-ec2 >>" \
              https://api.memstash.io/values/parameters.stack-create-ec2

  create-prometheus-ec2:
    parameters:
      stack-create-promet:
        type: string
        default: stack-name-udap
    docker:
      - image: amazon/aws-cli
    steps:
      - checkout
      - run:
          name: Install/version aws cli
          command: |
            # sudo apt update # Or without 'sudo'
            # sudo apt upgrade
            # sudo apt install python3-pip
            # pip3 install awscli --upgrade --user
            aws --version
      - run:
          name: Run aws cloudformation and create ec2 instance
          command: |
            export AWS_ACCESS_KEY_ID=$AWS_ACCESS_KEY_ID2
            export AWS_SECRET_ACCESS_KEY=$AWS_SECRET_ACCESS_KEY2
            # aws cloudformation wait stack-create-complete \
            aws cloudformation deploy \
            --template-file .circleci/files/prometheus.yml \
            --stack-name prometheus-ec2 \
            --parameter-overrides ID=<< parameters.stack-create-promet >>
            # --parameter-overrides ID=ec2-promet

  run-cloudfront:
    parameters:
      stack-name-param:
        type: string
        default: cloudf-udapeople
      s3-frontend-param:
        type: string
        default: s3-uda-deploy
    docker:
      - image: amazon/aws-cli
    steps:
      - checkout
      - run:
          name: Install/version aws cli
          command: |
            # sudo apt update # Or without 'sudo'
            # sudo apt upgrade
            # sudo apt install python3-pip
            # pip3 install awscli --upgrade --user
            aws --version
      - run:
          # https://aws.amazon.com/premiumsupport/knowledge-center/cloudformation-stack-export-name-error/
          # WorkflowID=<existing S3 bucket> e.g.:'s3-uda-deploy'
          name: Run aws cloudformation 
          command: |
            export AWS_ACCESS_KEY_ID=$AWS_ACCESS_KEY_ID2
            export AWS_SECRET_ACCESS_KEY=$AWS_SECRET_ACCESS_KEY2
            # aws cloudformation wait stack-create-complete \
            aws cloudformation deploy \
            --template-file .circleci/files/cloudfront.yml \
            --stack-name << parameters.stack-name-param >> \
            --parameter-overrides WorkflowID=<< parameters.s3-frontend-param >>
            # 'WorkflowID=s3-uda-deploy' same name created S3 bucket above

  stack-delete:
    parameters:
      stack-param-del:
        type: string
        default: stack-name-udap
    docker:
      - image: amazon/aws-cli
    steps:
      - checkout
      - store_test_results:
          path: test-results
      - run:
          name: Install/version aws cli
          command: |
            aws --version
      - run:
          name: Delete stack
          command: |
            export AWS_ACCESS_KEY_ID=$AWS_ACCESS_KEY_ID2
            export AWS_SECRET_ACCESS_KEY=$AWS_SECRET_ACCESS_KEY2            
            aws cloudformation delete-stack \
            --stack-name  << parameters.stack-param-del >>
            #
            # Store evidence on 'memstash.io'
            # echo "This is pipeline ID << pipeline.id >>"
            # echo "Stored pipeline ID: << pipeline.id >>_stack-delete"
            DATE=`date`
            curl -H "Content-Type: text/plain" \
              -H "token: 265a0727-db66-453a-8559-6b292b496502" \
              --request PUT --data "Circle - $DATE : << pipeline.id >>_stack-delete" \
              https://api.memstash.io/values/udapeople-stack-delete

  s3-delete:
    parameters:
      s3-param:
        type: string
        default: bucket-namex
    docker:
      - image: amazon/aws-cli
    steps:
      - checkout
      - store_test_results:
          path: test-results
      - run:
          name: Delete s3 bucket
          command: |
            export AWS_ACCESS_KEY_ID=$AWS_ACCESS_KEY_ID2
            export AWS_SECRET_ACCESS_KEY=$AWS_SECRET_ACCESS_KEY2
            aws s3 rb s3://<< parameters.s3-param >>
            # Deletes all objects and subfolders in the bucket and 
            # then removes the bucket.
            # aws s3 rb s3://<< parameters.s3-param >> --force

  ec2-delete:
    parameters:
      ec2-param:
        type: string
        default: i-5203422c    # Fake
    docker:
      - image: amazon/aws-cli
    steps:
      - checkout
      - store_test_results:
          path: test-results
      - run:
          name: Delete ec2 instance
          command: |
            export AWS_ACCESS_KEY_ID=$AWS_ACCESS_KEY_ID2
            export AWS_SECRET_ACCESS_KEY=$AWS_SECRET_ACCESS_KEY2
            aws ec2 terminate-instances \
            --instance-ids  << parameters.ec2-param >>

  run-cp2s3:
    docker:
      - image: amazon/aws-cli
      # amazon/aws-cli: aws command
      # - image: circleci/node:10.0.0
      # circleci/node:10.0.0: npm command
    steps:
      - checkout
      - run:
          name: Copy fronted/dist to s3 bucket
          command: |
            export AWS_ACCESS_KEY_ID=$AWS_ACCESS_KEY_ID2
            export AWS_SECRET_ACCESS_KEY=$AWS_SECRET_ACCESS_KEY2
            aws --version
            #
            # $ aws s3 cp ./dist s3://s3-uda-deploy --recursive \
            # --exclude "*.DS_Store" --acl public-read --cache-control \
            # public,max-age=604800 --dryrun --profile iam_user
            #
            # Or, use ansible:
            # if [ "${CIRCLE_BRANCH}" == "master" ]; then
            #   ansible-playbook playb_cp2s3.yml
            # fi
            # Store evidence on 'memstash.io'
            # echo "This is pipeline ID << pipeline.id >>"
            # echo "Stored pipeline ID: << pipeline.id >>_cp2s3"
            DATE=`date`
            curl -H "Content-Type: text/plain" \
              -H "token: 265a0727-db66-453a-8559-6b292b496502" \
              --request PUT --data "Circle - $DATE: << pipeline.id >>_cp2s3" \
              https://api.memstash.io/values/udapeople-cp2s3
            cd frontend
            # Commented during testing
            # aws s3 sync dist/ s3://s3-uda-deploy --acl public-read
            # curl -H "token: 265a0727-db66-453a-8559-6b292b496502" \
            #  --request GET https://api.memstash.io/values/udapeople-cp2s3
            

  check-curl-backend:
    parameters:
      ec2-name-param:
        type: string
        default: backend-uda-deploy3    
        # Main: backend-uda-deploy3 - should not fail
        # secondary: backend-uda-instancex on 'memstash.io'
    docker:
      - image: amazon/aws-cli
    steps:
      - checkout
      #- sayhello:
      #    to: "======== Lev Lev Lev ========="
      - smoke-roll-back-ec2:
          roll-ec2-param: << parameters.ec2-name-param >>

  check-curl-frontend:
    parameters:
      cloud-front-id0:
        type: string
        default: ELP62178K8WGU
      s3-name-param:
        type: string
        default: uda-bucketx	# Should not exist. The current working is: 's3-uda-deploy'
        # Main: s3-uda-deploy - should not fail
        # secondary: xx-uda-deploy on 'memstash.io'
    docker:
      - image: amazon/aws-cli
    steps:
      - checkout
      - smoke-roll-back-s3:
          cloud-front-id: << parameters.cloud-front-id0 >>
          current-s3-param: << parameters.s3-name-param >>

  deploy-ifmaster:
    docker:
      - image: amazon/aws-cli
    steps:
      - checkout
      - run:
          name: Deploy if Master branch
          command: |
            if [ "${CIRCLE_BRANCH}" == "master" ]; then
              # ansible-playbook site.yml
              echo "Master Branch - deploy site"
              exit 0
            else
              echo "Branch = ${CIRCLE_BRANCH}: NOT Master Branch -- Do not deploy site"
              exit 1
            fi

  jest-test-frontend:
    parameters:
      jest-frontend:
        type: boolean
        default: true
    docker:
      # - image: amazon/aws-cli
      - image: circleci/node:10.0.0
    steps:
      - checkout
      - run:
          name: Install JUnit coverage reporter
          command: |
            pwd
            cd frontend
            npm  add --dev jest-junit
            mkdir -p ~/reports/junit/
            pwd ; ls -asl
            echo "Where is ~/reports/junit/" >> ~/reports/junit/jest-test-frontend.txt
            ls -las ~/reports/junit/
            cat  ~/reports/junit/jest-test-frontend.txt
      - run:
          name: Run tests with JUnit as reporter
          command: |
            pwd
            cd frontend
            npm  add --dev jest-junit
            node_modules/.bin/jest --ci --runInBand --reporters=default \
              --reporters=jest-junit
          environment:
            JEST_JUNIT_OUTPUT_DIR: ~/reports/junit/
      - store_test_results:
          path: ~/reports/junit/
      - store_artifacts:
          path: ~/reports/junit

  jest-test-backend:
    docker:
      # - image: amazon/aws-cli
      - image: circleci/node:10.0.0
    steps:
      - checkout
      - run:
          name: Install JUnit coverage reporter
          command: |
            pwd
            cd backend
            npm  add --dev jest-junit
            mkdir -p ~/reports/junit/
            pwd ; ls -asl
            echo "Where is ~/reports/junit/" >> ~/reports/junit/jest-test-backend.txt
            ls -las ~/reports/junit/
            cat  ~/reports/junit/jest-test-backend.txt
      - run:
          name: Run tests with JUnit as reporter
          command: |
            pwd
            cd backend
            npm  add --dev jest-junit
            node_modules/.bin/jest --ci --runInBand --reporters=default \
              --reporters=jest-junit \
              --testResultsProcessor="jest-junit"
          environment:
            JEST_JUNIT_OUTPUT_DIR: ~/reports/junit/
      - store_test_results:
          path: ~/reports/junit/
      - store_artifacts:
          path: ~/reports/junit

parameters:
  deploy-s3:
    type: boolean
    default: true
  # A parameter per package
  deploy-ec2:
    type: boolean
    default: true
  deploy2s3:
    type: boolean
    default: false
  destroy-s3:
    type: boolean
    default: false
  # A parameter per package
  destroy-ec2:
    type: boolean
    default: false
  lint:
    type: boolean
    default: false
  smoke:
    type: boolean
    default: true
  create-infra-allow:
    type: boolean
    default: false
  jest2:
    type: boolean
    default: false
  jest-checked:
    type: boolean
    default: true
  say-hello-only:
    type: boolean
    default: false
  stash-token:
    type: string
    default: 265a0727-db66-453a-8559-6b292b496502
#Stash Key for new create backend ec2: parameters.stack-create-ec2
#Stash Key for new create backend s3: parameters.stack-create-s3

workflows:
  version: 2

  create-infra:         # conditional-workflow
    when: 
      and:          # All must be true to trigger
        - equal: [ master, << pipeline.git.branch >> ]
        - and: [ << pipeline.parameters.create-infra-allow >> ]
        # - and: [ << pipeline.parameters.jest-checked >> ]
        - and: [ << pipeline.parameters.deploy-ec2 >> ]
        - and: [ << pipeline.parameters.deploy-s3 >> ]
        # - equal: [ uda-bucketx, << pipeline.parameters.stack-param >> ]
        # - not: << pipeline.parameters.param1 >>
        # - or: [ << pipeline.parameters.param1 >>, << pipeline.parameters.param2 >> ]

    jobs:
      # - job-on-condition
      - create-frontend-s3:
          context: ci-uda-context
          stack-create-s3:  uda-bucketx        # 'A-@!#incorrect' should fail.
          # 'uda-bucketx' should be the last deployed s3 frontend bucket with success.
      - create-backend-ec2:
          context: ci-uda-context
          stack-create-ec2: uda-instancex      # uda-instancex
          # The template adds 'backend-' -> backend-uda-instancex
          #requires:
          #  - create-frontend-s3
      - create-prometheus-ec2:
          context: ci-uda-context
          stack-create-promet: udap-prometx
          requires:
            - create-frontend-s3
            - create-backend-ec2
      - run-cp2s3:
          context: ci-uda-context
          requires:
            - create-frontend-s3
            - create-backend-ec2
            # - deploy-ifmaster


  deploy-code:
    when:  << pipeline.parameters.deploy2s3 >>
    jobs:
      - run-cp2s3:
        filters:
          branches:
              - master
              #- beta
          context: ci-uda-context
          #requires:
          #  - create-frontend-s3
          #  - create-backend-ec2
          #  # - deploy-ifmaster


  clean-up-old-stacks:
    when:           # << pipeline.parameters.destroy-s3 >>
      and:
        - equal: [ master, << pipeline.git.branch >> ]
        - or: [ << pipeline.parameters.destroy-ec2 >> , << pipeline.parameters.destroy-s3 >> ]

    jobs:
      - stack-delete:
          context: ci-uda-context
          stack-param-del: stack-name-udap
      - s3-delete:
          context: ci-uda-context
          s3-param: udapeople-uda-bucketx
          #requires:
          #  create-frontend-s3
      - ec2-delete:
          context: ci-uda-context
          ec2-param: i-04ea18fd6a4a5379f
          #requires:
          #  - create-backend-ec2

  check-code-lint:
    when: << pipeline.parameters.lint >> 
    jobs:
      - lint-frontend
      - lint-backend


#-      # - run-frontend
#-      # - run-backend


  smoke-test:
    when: << pipeline.parameters.smoke >> 
    jobs:
      - check-curl-backend:
          context: ci-uda-context
          ec2-name-param: backend-uda-deploy3
          #requires:
          #  - check-curl-frontend
          # backend-uda-instancex -  should fail
          # ec2-name-param: backend-uda-deploy3 - should not fail
          #requires:
          #  - create-backend-ec2
          # Main: backend-uda-deploy3 - should not fail
          # secondary: backend-uda-instancex on 'memstash.io'
          # memstash.io key: parameters.stack-create-ec2
          # Old deployed with success: backend-uda-instancex
      - check-curl-frontend:
          context: ci-uda-context
          cloud-front-id0: ELP62178K8WGU
          s3-name-param: s3-uda-deploy
          #requires:
          #  - check-curl-backend
          # uda-bucketx: should fail
          # s3-uda-deploy: should not fail
          #requires:
          #  - check-curl-backend
          # memstash.io key: parameters.stack-create-s3
          # Old deployed with success: uda-bucketx
      - run-cloudfront:
          context: ci-uda-context
          stack-name-param: cloudf-udapeople
          s3-frontend-param: s3-uda-deploy
          # type: approval  # <<< This key-value pair will set your 
          # workflow to a status of "On Hold"
          requires:
            - check-curl-frontend
            #- create-backend-ec2
            #- create-prometheus-ec2

  check-jest:
    when: << pipeline.parameters.jest2 >>
    jobs:
      - jest-test-frontend
          #requires:
          #  - deploy-ifmaster

      - jest-test-backend
          #requires:
          #  - deploy-ifmaster

  say-hello:
    when: << pipeline.parameters.say-hello-only >>
    jobs:
      - hello-world-udapeople
      # - aws-cli-example:
      #    context: ci-uda-context
